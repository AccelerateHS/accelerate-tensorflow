
#include <iostream>
#include <stdint.h>

#include "tensorflow/lite/interpreter.h"
#include "tensorflow/lite/kernels/register.h"
#include "tensorflow/lite/model.h"
#include "tensorflow/lite/optional_debug_tools.h"

#include "edgetpu.h"

// NOTE: Must match encoding generated by 'tagOfInt'
//
typedef enum __attribute__((__packed__)) {
    TypeInt8,
    TypeInt16,
    TypeInt32,
    TypeInt64,
    TypeWord8,
    TypeWord16,
    TypeWord32,
    TypeWord64,
    TypeHalf,
    TypeFloat,
    TypeDouble
} TensorType;

std::unique_ptr<tflite::Interpreter>
BuildEdgeTpuInterpreter
(
    const tflite::FlatBufferModel& model,
    edgetpu::EdgeTpuContext* edgetpu_context
)
{
  tflite::ops::builtin::BuiltinOpResolver resolver;
  resolver.AddCustom(edgetpu::kCustomOp, edgetpu::RegisterCustomOp());

  std::unique_ptr<tflite::Interpreter> interpreter;
  if (tflite::InterpreterBuilder(model, resolver)(&interpreter) != kTfLiteOk) {
    std::cerr << "Failed to build TPU interpreter" << std::endl;
  }

  // Bind given context with interpreter
  interpreter->SetExternalContext(kTfLiteEdgeTpuContext, edgetpu_context);
  interpreter->SetNumThreads(1);

  if (interpreter->AllocateTensors() != kTfLiteOk) {
    std::cerr << "Failed to allocate TPU tensors" << std::endl;
  }

  return interpreter;
}

extern "C"
void
edgetpu_run
(
    const char* model_buffer,
    const int64_t buffer_size,
    const char** tensor_name,
    uint8_t* tensor_type,
    uint8_t** tensor_data,
    int64_t* tensor_size_bytes,
    int64_t tensor_count
)
{
  // Load the TPU model
  // std::unique_ptr<tflite::FlatBufferModel> model = tflite::FlatBufferModel::BuildFromFile(model_path);
  std::unique_ptr<tflite::FlatBufferModel> model = tflite::FlatBufferModel::BuildFromBuffer(model_buffer, buffer_size);

  // Get EdgeTPU context
  std::shared_ptr<edgetpu::EdgeTpuContext> context = edgetpu::EdgeTpuManager::GetSingleton()->OpenDevice();
  std::unique_ptr<tflite::Interpreter> interpreter = BuildEdgeTpuInterpreter(*model, context.get());

  // Push the data to each named input tensor
  auto input_tensors = interpreter->inputs();
  for (int64_t i = 0; i < input_tensors.size(); ++i) {
    auto input_name = interpreter->GetInputName(i);

    for (int64_t j = 0; j < tensor_count; ++j) {
      if (0 == strcmp(input_name, tensor_name[j])) {
        switch ((TensorType) tensor_type[j]) {
          case TypeInt8:   memcpy(interpreter->typed_input_tensor<int8_t>(i),   tensor_data[j], tensor_size_bytes[j]); break;
          case TypeInt16:  memcpy(interpreter->typed_input_tensor<int16_t>(i),  tensor_data[j], tensor_size_bytes[j]); break;
          case TypeInt32:  memcpy(interpreter->typed_input_tensor<int32_t>(i),  tensor_data[j], tensor_size_bytes[j]); break;
          case TypeInt64:  memcpy(interpreter->typed_input_tensor<int64_t>(i),  tensor_data[j], tensor_size_bytes[j]); break;
          case TypeWord8:  memcpy(interpreter->typed_input_tensor<uint8_t>(i),  tensor_data[j], tensor_size_bytes[j]); break;
          case TypeWord16: memcpy(interpreter->typed_input_tensor<uint16_t>(i), tensor_data[j], tensor_size_bytes[j]); break;
          case TypeWord32: memcpy(interpreter->typed_input_tensor<uint32_t>(i), tensor_data[j], tensor_size_bytes[j]); break;
          case TypeWord64: memcpy(interpreter->typed_input_tensor<uint64_t>(i), tensor_data[j], tensor_size_bytes[j]); break;
          case TypeHalf:   memcpy(interpreter->typed_input_tensor<uint16_t>(i), tensor_data[j], tensor_size_bytes[j]); break;
          case TypeFloat:  memcpy(interpreter->typed_input_tensor<float>(i),    tensor_data[j], tensor_size_bytes[j]); break;
          case TypeDouble: memcpy(interpreter->typed_input_tensor<double>(i),   tensor_data[j], tensor_size_bytes[j]); break;
        }
        break;
      }
    }
  }

  // Run the interpreter
  interpreter->Invoke();

  // Extract the data from each output tensor
  auto output_tensors = interpreter->outputs();
  for (int64_t i = 0; i < output_tensors.size(); ++i) {
    auto output_name = interpreter->GetOutputName(i);

    for (int64_t j = 0; j < tensor_count; ++j) {
      if (0 == strcmp(output_name, tensor_name[j])) {
        // Assumes that the size of the output tensor data is known statically,
        // but this is already required for tflite
        switch ((TensorType) tensor_type[j]) {
          case TypeInt8:   memcpy(tensor_data[j], interpreter->typed_input_tensor<int8_t>(i),   tensor_size_bytes[j]); break;
          case TypeInt16:  memcpy(tensor_data[j], interpreter->typed_input_tensor<int16_t>(i),  tensor_size_bytes[j]); break;
          case TypeInt32:  memcpy(tensor_data[j], interpreter->typed_input_tensor<int32_t>(i),  tensor_size_bytes[j]); break;
          case TypeInt64:  memcpy(tensor_data[j], interpreter->typed_input_tensor<int64_t>(i),  tensor_size_bytes[j]); break;
          case TypeWord8:  memcpy(tensor_data[j], interpreter->typed_input_tensor<uint8_t>(i),  tensor_size_bytes[j]); break;
          case TypeWord16: memcpy(tensor_data[j], interpreter->typed_input_tensor<uint16_t>(i), tensor_size_bytes[j]); break;
          case TypeWord32: memcpy(tensor_data[j], interpreter->typed_input_tensor<uint32_t>(i), tensor_size_bytes[j]); break;
          case TypeWord64: memcpy(tensor_data[j], interpreter->typed_input_tensor<uint64_t>(i), tensor_size_bytes[j]); break;
          case TypeHalf:   memcpy(tensor_data[j], interpreter->typed_input_tensor<uint16_t>(i), tensor_size_bytes[j]); break;
          case TypeFloat:  memcpy(tensor_data[j], interpreter->typed_input_tensor<float>(i),    tensor_size_bytes[j]); break;
          case TypeDouble: memcpy(tensor_data[j], interpreter->typed_input_tensor<double>(i),   tensor_size_bytes[j]); break;
        }
        break;
      }
    }
  }
}

